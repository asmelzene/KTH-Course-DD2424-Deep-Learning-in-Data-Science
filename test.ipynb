{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import dataset \n",
    "#import layer\n",
    "#from layer import Linear, Softmax\n",
    "\n",
    "import gradient\n",
    "import dataset\n",
    "import computations\n",
    "import layer\n",
    "#from layer import Linear, Softmax, Gradient\n",
    "import network\n",
    "\n",
    "network1 = network.Network()\n",
    "import dataset\n",
    "cifar = dataset.CIFAR_IMAGES()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#X = np.empty(shape=[0, n])\n",
    "xx=np.empty(shape=[0, 0])\n",
    "np.append(xx, [[1,2,3], [3,4,5]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin1 = Linear()\n",
    "print(type(lin1))\n",
    "\n",
    "if type(lin1) == Linear:\n",
    "    print('correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = dataset.CIFAR_IMAGES()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=23\n",
    "y=np.zeros((10,2))\n",
    "z = x or y\n",
    "print(z)\n",
    "print(y)\n",
    "print(y.T)\n",
    "print(y.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 50000)\n",
      "(10, 50000)\n",
      "(50000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n[self.train_X, self.train_Y, self.train_y] = self.X_all[:, :45000]\\n[self.validation_X, self.validation_Y, self.validation_y] = self.X_all[:, 45000:]\\n[self.test_X, self.test_Y, self.test_y] = cifar.load_batch_a1(filePathList[1])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePathLocal_labels = 'Dataset/batches.meta'\n",
    "filePathLocal_batch = 'Dataset/data_batch_1'\n",
    "filePathLocal_data_TRAIN = 'Dataset/data_batch_1'\n",
    "filePathLocal_data_VALIDATION = 'Dataset/data_batch_2'\n",
    "filePathLocal_data_TEST = 'Dataset/test_batch'\n",
    "\n",
    "filePathLocal_data_ALL = ['Dataset/data_batch_1', 'Dataset/data_batch_2', 'Dataset/data_batch_3', 'Dataset/data_batch_4', 'Dataset/data_batch_5']\n",
    "\n",
    "\n",
    "filePathList = (filePathLocal_data_ALL, filePathLocal_data_TEST)\n",
    "#network1.ReadData_Exercise4(cifar, filePathList)\n",
    "\n",
    "list_X_all = []\n",
    "list_Y_all = []\n",
    "list_y_all = []\n",
    "        \n",
    "for file in filePathList[0]:\n",
    "    [temp_train_X, temp_train_Y, temp_train_y] = cifar.load_batch_a1(file)\n",
    "    list_X_all.append(temp_train_X)\n",
    "    list_Y_all.append(temp_train_Y)\n",
    "    list_y_all.append(temp_train_y)\n",
    "\n",
    "#X_all = np.hstack([b.images for b in list_X_all])    \n",
    "\n",
    "X_all = list_X_all[0]\n",
    "Y_all = list_Y_all[0]\n",
    "y_all = list_y_all[0]\n",
    "for i in range(len(list_X_all)): \n",
    "    if i != 0:\n",
    "        X_all = np.hstack((X_all, list_X_all[i]))\n",
    "        Y_all = np.hstack((Y_all, list_Y_all[i]))\n",
    "        y_all = np.append(y_all, list_y_all[i])\n",
    "\n",
    "print(X_all.shape)\n",
    "print(Y_all.shape)\n",
    "print(y_all.shape)\n",
    "    \n",
    "'''\n",
    "[self.train_X, self.train_Y, self.train_y] = self.X_all[:, :45000]\n",
    "[self.validation_X, self.validation_Y, self.validation_y] = self.X_all[:, 45000:]\n",
    "[self.test_X, self.test_Y, self.test_y] = cifar.load_batch_a1(filePathList[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePathLocal_labels = 'Dataset/batches.meta'\n",
    "filePathLocal_batch = 'Dataset/data_batch_1'\n",
    "filePathLocal_data_TRAIN = 'Dataset/data_batch_1'\n",
    "filePathLocal_data_VALIDATION = 'Dataset/data_batch_2'\n",
    "filePathLocal_data_TEST = 'Dataset/test_batch'\n",
    "\n",
    "filePathLocal_data_ALL = ['Dataset/data_batch_1', 'Dataset/data_batch_2', 'Dataset/data_batch_3', 'Dataset/data_batch_4', 'Dataset/data_batch_5']\n",
    "\n",
    "\n",
    "filePathList = (filePathLocal_data_ALL, filePathLocal_data_TEST)\n",
    "network1.ReadData_Exercise4(cifar, filePathList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 45000)\n",
      "(10, 45000)\n",
      "(45000,)\n",
      "(3072, 5000)\n",
      "(10, 5000)\n",
      "(5000,)\n",
      "(3072, 10000)\n",
      "(10, 10000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(network1.train_X.shape)\n",
    "print(network1.train_Y.shape)\n",
    "print(network1.train_y.shape)\n",
    "\n",
    "print(network1.validation_X.shape)\n",
    "print(network1.validation_Y.shape)\n",
    "print(network1.validation_y.shape)\n",
    "\n",
    "print(network1.test_X.shape)\n",
    "print(network1.test_Y.shape)\n",
    "print(network1.test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list_y_all:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=np.hstack((list_X_all[0], list_X_all[1]))\n",
    "ct.shape\n",
    "ct=np.hstack((ct, list_X_all[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X_all = [0, 0, 0, 0, 0]\n",
    "ar1=np.zeros(2)\n",
    "print(ar1)\n",
    "#t = np.hstack(list_X_all)\n",
    "list_X_all[0] = ar1\n",
    "print(list_X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X_all=[]\n",
    "ar1=np.zeros(2)\n",
    "list_X_all.append(ar1)\n",
    "print(list_X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1],[2],[3]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coarse_Search(l_min, l_max):\n",
    "    l = l_min + (l_max - l_min) * np.random.uniform(0,1)\n",
    "    lambda_coarse = pow(10, l)\n",
    "    return lambda_coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009759311131665088"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coarse_Search(-5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.780428561789766"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * np.random.uniform(0,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
